{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd05759b",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid RosyBrown\"> </hr>\n",
    "<hr style=\"border:1px solid Wheat\"> </hr>\n",
    "\n",
    "# Constrained Markov Clustering\n",
    "\n",
    "<hr style=\"border:1px solid Wheat\"> </hr>\n",
    "<hr style=\"border:2px solid RosyBrown\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacd5a2a",
   "metadata": {},
   "source": [
    "Load all packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fdb2bae0-4c9a-488a-940b-cedfa933c2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "# Import modules\n",
    "from sklearn import datasets, decomposition\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "# Import custom classes and functions\n",
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0, module_path)\n",
    "    \n",
    "from models.data_gen import dataGen\n",
    "from models.CoMaC import CoMaC\n",
    "\n",
    "from utils.callback import save_results\n",
    "from utils.helperFunc import partition_to_labels, generate_int_labels\n",
    "from utils.plotting import show_clustering, show_transition_prob\n",
    "#------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b4157a54-9e86-45dc-ac25-38602a4d4486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRIS dataset with 4 features, 150 samples and 3 classes.\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------#\n",
    "# Select from different datasets\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "dataset_str = 'IRIS'\n",
    "\n",
    "if dataset_str == 'IRIS':\n",
    "    iris = datasets.load_iris()\n",
    "    X = iris.data[:, :]\n",
    "    labels_true = iris.target\n",
    "\n",
    "elif dataset_str == 'WINE':\n",
    "    wine = datasets.load_wine()\n",
    "    X = wine.data[:, :]\n",
    "    labels_true = wine.target\n",
    "\n",
    "elif dataset_str == 'WINE_SCALED':\n",
    "    wine_df = pd.read_csv(\"../data/rand_samples_links/wine-scaled.in\",\n",
    "                          header=None, delimiter=\",\")\n",
    "    X = wine_df.loc[:, 0:12].to_numpy()\n",
    "    labels_true = wine_df.loc[:,13].to_numpy()\n",
    "\n",
    "elif dataset_str == 'GLASS':\n",
    "    glass_df = pd.read_csv(\"../data/data-sets/glass.csv\", header=None)\n",
    "    X = glass_df.loc[:, 0:8].to_numpy()\n",
    "    labels_true = glass_df.loc[:, 9].to_numpy()\n",
    "\n",
    "elif dataset_str == 'ECOLI':\n",
    "    ecoli_df = pd.read_csv(\"../data/data-sets/ecoli.csv\", header=None)\n",
    "    X = ecoli_df.loc[:, 0:6].to_numpy()\n",
    "    pca = decomposition.PCA(n_components=5)\n",
    "    pca.fit(X)\n",
    "    X = pca.transform(X)\n",
    "    labels_true = ecoli_df.loc[:, 7].to_numpy()\n",
    "    X = X[:327, :]\n",
    "    labels_true = labels_true[:327]\n",
    "\n",
    "elif dataset_str == 'VERTEBRAL':\n",
    "    vertebral_df = pd.read_csv(\"../data/data-sets/vertebral.data\",\n",
    "                               skiprows=[0], header=None, delimiter=\" \")\n",
    "    X = vertebral_df.loc[:, 0:5].to_numpy()\n",
    "    labels_df = pd.read_csv(\"../data/reference-labelling/vertebral.ref\",\n",
    "                            skiprows=[0], header=None, delimiter=\" \")\n",
    "    labels_true = labels_df.to_numpy()\n",
    "\n",
    "elif dataset_str == 'SEGMENTATION':\n",
    "    segmentation_df = pd.read_csv(\"../data/data-sets/segmentation.data\",\n",
    "                                  skiprows=[0], header=None, delimiter=\" \")\n",
    "    X = segmentation_df.loc[:, 0:4].to_numpy()\n",
    "    labels_df = pd.read_csv(\"../data/reference-labelling/segmentation.ref\",\n",
    "                            skiprows=[0], header=None, delimiter=\" \")\n",
    "    labels_true = labels_df.to_numpy()\n",
    "\n",
    "elif dataset_str == 'USER':\n",
    "    user_df = pd.read_csv(\"../data/data-sets/user.data\",\n",
    "                          skiprows=[0], header=None, delimiter=\" \")\n",
    "    X = user_df.loc[:, 0:4].to_numpy()\n",
    "    labels_df = pd.read_csv(\"../data/reference-labelling/user.ref\",\n",
    "                            skiprows=[0], header=None, delimiter=\" \")\n",
    "    labels_true = labels_df.to_numpy()\n",
    "\n",
    "else:\n",
    "    dataGenerator = dataGen()\n",
    "    P, V_true, X = dataGenerator.generateCircles()\n",
    "    labels_true = partition_to_labels(V_true)\n",
    "\n",
    "labels_true = generate_int_labels(labels_true)\n",
    "M = len(np.unique(labels_true))\n",
    "\n",
    "print(f'{dataset_str} dataset with {X.shape[1]} features, {X.shape[0]} samples and {M} classes.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9318859-09b8-4206-92cd-95dbafcaf442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      " Annealing Algorithm: final beta = 0\n",
      "Starting with beta = 1\n",
      "*************************Clustering Finished!*************************\n",
      "Starting with beta = 0.9\n",
      "*************************Clustering Finished!*************************\n",
      "Starting with beta = 0.8\n",
      "*************************Clustering Finished!*************************\n",
      "Starting with beta = 0.7\n",
      "*************************Clustering Finished!*************************\n",
      "Starting with beta = 0.6\n",
      "*************************Clustering Finished!*************************\n",
      "Starting with beta = 0.5\n",
      "*************************Clustering Finished!*************************\n",
      "Starting with beta = 0.4\n",
      "*************************Clustering Finished!*************************\n",
      "Starting with beta = 0.3\n",
      "*************************Clustering Finished!*************************\n",
      "Starting with beta = 0.2\n",
      "*************************Clustering Finished!*************************\n",
      "Starting with beta = 0.1\n",
      "*************************Clustering Finished!*************************\n",
      "Starting with beta = 0.0\n",
      "*************************Clustering Finished!*************************\n",
      "********** Sequential Algorithm: 1.0**********\n",
      "*************************Clustering Finished!*************************\n",
      "********** Sequential Algorithm: 0.9**********\n",
      "*************************Clustering Finished!*************************\n",
      "********** Sequential Algorithm: 0.8**********\n",
      "*************************Clustering Finished!*************************\n",
      "********** Sequential Algorithm: 0.7**********\n",
      "*************************Clustering Finished!*************************\n",
      "********** Sequential Algorithm: 0.6**********\n",
      "*************************Clustering Finished!*************************\n",
      "********** Sequential Algorithm: 0.5**********\n",
      "*************************Clustering Finished!*************************\n",
      "********** Sequential Algorithm: 0.4**********\n",
      "*************************Clustering Finished!*************************\n",
      "********** Sequential Algorithm: 0.3**********\n",
      "*************************Clustering Finished!*************************\n",
      "********** Sequential Algorithm: 0.2**********\n",
      "*************************Clustering Finished!*************************\n",
      "********** Sequential Algorithm: 0.1**********\n",
      "*************************Clustering Finished!*************************\n",
      "********** Sequential Algorithm: 0.0**********\n",
      "*************************Clustering Finished!*************************\n",
      " beta=[1.  0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0. ]\n",
      " annealing: NMI = [8.99693545e-01 8.99693545e-01 8.05693691e-01 9.14362531e-01\n",
      " 9.14362531e-01 9.14362531e-01 4.81512410e-01 9.19800611e-04\n",
      " 2.35271500e-03 7.76771804e-04 7.26416288e-04] \n",
      " sequential: NMI = [0.89969355 0.80307039 0.91436253 0.91436253 0.91436253 0.91436253\n",
      " 0.77202086 0.00272489 0.00226164 0.0039966  0.00110639] \n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------#\n",
    "# Parameters\n",
    "\n",
    "final_beta=0\n",
    "step_size=-0.1\n",
    "\n",
    "N_iter=1\n",
    "knns=20\n",
    "restarts=5\n",
    "percentage_vec=[0.2]\n",
    "flag_save_results=False\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "for iteration, percentage in itertools.product(range(N_iter), percentage_vec):\n",
    "\n",
    "    #--------------------------------------------------------------------------#\n",
    "    # Initialize and generate constraints\n",
    "    comac = CoMaC(M=M, knns=knns, restarts=restarts)\n",
    "    comac.constraints(X, labels_true, percentage=percentage,\n",
    "                      wrong_percentage=0, ClassLabels='All')\n",
    "    #--------------------------------------------------------------------------#\n",
    "\n",
    "    #--------------------------------------------------------------------------#\n",
    "    # Annealing algorithm\n",
    "    print('~'*80 + f'\\n Annealing Algorithm: final beta = {final_beta}')\n",
    "    cost_ann, V_ann, beta_vec = comac.cluster_ann(X, final_beta=final_beta, \n",
    "                                                  step_size=step_size)\n",
    "    #--------------------------------------------------------------------------#\n",
    "\n",
    "    #--------------------------------------------------------------------------#\n",
    "    # Sequential algorithm\n",
    "    V_seq = np.zeros_like(V_ann)\n",
    "    cost_seq = np.zeros_like(beta_vec)\n",
    "    for idx, beta in enumerate(beta_vec):\n",
    "        print('*'*10 + f' Sequential Algorithm: {beta}' + '*'*10)\n",
    "        cost, V = comac.cluster_seq(X, beta=beta)\n",
    "        cost_seq[idx] = cost\n",
    "        V_seq[idx,:,:] = V\n",
    "    #--------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "    #--------------------------------------------------------------------------#\n",
    "    # Generate labels, compute NMI\n",
    "    NMI_ann = np.zeros_like(beta_vec)\n",
    "    NMI_seq = np.zeros_like(beta_vec)\n",
    "    labels_ann = []\n",
    "    labels_seq = []\n",
    "\n",
    "    for idx, beta in enumerate(beta_vec):\n",
    "        labels_ann.append( partition_to_labels(V_ann[idx, :, :]) )\n",
    "        labels_seq.append( partition_to_labels(V_seq[idx, :, :]) )\n",
    "        NMI_ann[idx] = normalized_mutual_info_score(labels_true,\n",
    "                                                    labels_ann[-1])\n",
    "        NMI_seq[idx] = normalized_mutual_info_score(labels_true,\n",
    "                                                    labels_seq[-1])\n",
    "        \n",
    "    print(f' beta={beta_vec}\\n annealing: NMI = {NMI_ann} \\n sequential: NMI = {NMI_seq} ')\n",
    "    #--------------------------------------------------------------------------#\n",
    "\n",
    "    #--------------------------------------------------------------------------#\n",
    "    # Save results\n",
    "    if flag_save_results:\n",
    "\n",
    "        save_results(iteration=iteration, \n",
    "                     dataset_str=dataset_str, \n",
    "                     beta_vec=beta_vec, \n",
    "                     knns=knns, \n",
    "                     restarts=restarts, \n",
    "                     labels_ann=labels_ann, \n",
    "                     labels_seq=labels_seq, \n",
    "                     NMI_ann=NMI_ann, \n",
    "                     NMI_seq=NMI_seq,\n",
    "                     percentage=percentage, \n",
    "                     csv_string='Results.csv')\n",
    "    #--------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80fb004-3bf7-4014-8e8d-09ab681e48be",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid DarkKhaki\"> </hr>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8fea633",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid IndianRed\"> </hr>\n",
    "\n",
    "## Algorithm 1\n",
    "#### Sequential Generalized Information-Theoretic Markov Aggregation\n",
    "\n",
    "<hr style=\"border:1px solid LightSalmon\"> </hr>\n",
    "\n",
    "1:  **function** $g = \\textsf{sGITMA}( \\mathbb{P}, \\beta, |\\mathcal{Y}|, \\text{#iter}_{\\text{max}}, \\text{optional: initial aggregation function } g_{init} ) $\n",
    "\n",
    "2:  &emsp;**if** $g_{init}$ is empty **then** &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; $\\triangleright$ *Initialization*\n",
    "\n",
    "3: &emsp;&emsp; $ g \\leftarrow \\text{Random Aggregation Function} $\n",
    "              \n",
    "4: &emsp;**else**\n",
    "       \n",
    "5: &emsp;&emsp; $ g \\leftarrow g_{init} $\n",
    "\n",
    "6: &emsp;**end if**\n",
    "\n",
    "7: &emsp; #iter $\\leftarrow 0$\n",
    "\n",
    "8: &emsp;**while** #iter < #iter$_{max}$ **do** &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; $\\triangleright$ *Main Loop*\n",
    "\n",
    "9: &emsp;&emsp; **for** all elements $x \\in \\mathcal{X}$ **do** &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; $~~ \\triangleright$ *Optimizing g*\n",
    "\n",
    "10: &emsp;&emsp;&emsp; **for** all aggregate states $y \\in \\mathcal{Y}$ **do**\n",
    "\n",
    "11: &emsp;&emsp;&emsp;&emsp; $ g_y(x') = \\begin{cases} g(x') ~~~ &x'\\neq x \\\\ y ~~~ &x'=x \\end{cases} $ &emsp;&emsp;&emsp;&emsp; $\\triangleright$ *Assign* $x$\n",
    "\n",
    "12: &emsp;&emsp;&emsp;&emsp; $C_{g_y} = \\mathcal{C}_\\beta (\\mathbf{X}, g_y)$\n",
    "\n",
    "13: &emsp;&emsp;&emsp; **end for**\n",
    "\n",
    "14: &emsp;&emsp;&emsp; $g = \\underset{g_y}{arg\\,min} C_{g_y}$ &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; $~~ \\triangleright$ *(break ties)*\n",
    "\n",
    "15: &emsp;&emsp; **end for**\n",
    "\n",
    "16: &emsp;&emsp; #iter $\\leftarrow$ #iter + 1\n",
    "\n",
    "17: &emsp; **end while**\n",
    "\n",
    "18: **end function**\n",
    "\n",
    "<hr style=\"border:1px solid LightSalmon\"> </hr>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf2dc76",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note:</b> Algorithm 1 might not converge to a global minimum but get stuck in poor local minima. For small values of $\\beta$ this is happening often. Therefore, an initialization is chosen close to a \"good\" local optimum: re-use the function $g$ obtained for a large value of $\\beta$ as initialization. This annealing is performed in Algorithm 2.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0658a4ef",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid IndianRed\"> </hr>\n",
    "\n",
    "## Algorithm 2\n",
    "#### $\\beta$-Annealing Information-Theoretic Markov Aggregation\n",
    "\n",
    "<hr style=\"border:1px solid LightSalmon\"> </hr>\n",
    "\n",
    "1:  **function** $g = \\textsf{AnnITMA}( \\mathbb{P}, \\beta_{target}, |\\mathcal{Y}|, \\text{#iter}_{\\text{max}}, \\Delta ) $\n",
    "\n",
    "2: &emsp; $\\beta \\leftarrow 1$ \n",
    "\n",
    "3: &emsp; $g = \\textsf{sGITMA}( \\mathbb{P}, \\beta, |\\mathcal{Y}|, \\text{#iter}_{\\text{max}}) $\n",
    "\n",
    "4: &emsp; **while** $\\beta > \\beta_{target}$ **do** \n",
    "              \n",
    "5: &emsp;&emsp; $\\beta \\leftarrow \\text{max}\\{ \\beta - \\Delta, \\beta_{target} \\}$ \n",
    "\n",
    "6: &emsp;&emsp; $g = \\textsf{AnnITMA}( \\mathbb{P}, \\beta_{target}, |\\mathcal{Y}|, \\text{#iter}_{\\text{max}}, g) $\n",
    "\n",
    "7: &emsp; **end while**\n",
    "\n",
    "8: **end function**\n",
    "\n",
    "<hr style=\"border:1px solid LightSalmon\"> </hr>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
