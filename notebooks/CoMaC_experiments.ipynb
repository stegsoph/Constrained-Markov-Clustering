{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd05759b",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid RosyBrown\"> </hr>\n",
    "<hr style=\"border:1px solid Wheat\"> </hr>\n",
    "\n",
    "# Constrained Markov Clustering\n",
    "\n",
    "<hr style=\"border:1px solid Wheat\"> </hr>\n",
    "<hr style=\"border:2px solid RosyBrown\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacd5a2a",
   "metadata": {},
   "source": [
    "Load all packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fdb2bae0-4c9a-488a-940b-cedfa933c2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "# Import modules\n",
    "from sklearn import datasets, decomposition\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "# Import custom classes and functions\n",
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0, module_path)\n",
    "    \n",
    "from models.data_gen import dataGen\n",
    "from models.CoMaC import CoMaC\n",
    "\n",
    "from utils.callback import save_results\n",
    "from utils.helperFunc import partition_to_labels, generate_int_labels\n",
    "from utils.plotting import show_clustering, show_transition_prob\n",
    "#------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4157a54-9e86-45dc-ac25-38602a4d4486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CIRCLES dataset with 2 features, 180 samples and 3 classes.\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------#\n",
    "# Select from different datasets\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "dataset_str = 'CIRCLES'\n",
    "\n",
    "if dataset_str == 'IRIS':\n",
    "    iris = datasets.load_iris()\n",
    "    X = iris.data[:, :]\n",
    "    labels_true = iris.target\n",
    "\n",
    "elif dataset_str == 'WINE':\n",
    "    wine = datasets.load_wine()\n",
    "    X = wine.data[:, :]\n",
    "    labels_true = wine.target\n",
    "\n",
    "elif dataset_str == 'WINE_SCALED':\n",
    "    wine_df = pd.read_csv(\"../data/rand_samples_links/wine-scaled.in\",\n",
    "                          header=None, delimiter=\",\")\n",
    "    X = wine_df.loc[:, 0:12].to_numpy()\n",
    "    labels_true = wine_df.loc[:,13].to_numpy()\n",
    "\n",
    "elif dataset_str == 'GLASS':\n",
    "    glass_df = pd.read_csv(\"../data/data-sets/glass.csv\", header=None)\n",
    "    X = glass_df.loc[:, 0:8].to_numpy()\n",
    "    labels_true = glass_df.loc[:, 9].to_numpy()\n",
    "\n",
    "elif dataset_str == 'ECOLI':\n",
    "    ecoli_df = pd.read_csv(\"../data/data-sets/ecoli.csv\", header=None)\n",
    "    X = ecoli_df.loc[:, 0:6].to_numpy()\n",
    "    pca = decomposition.PCA(n_components=5)\n",
    "    pca.fit(X)\n",
    "    X = pca.transform(X)\n",
    "    labels_true = ecoli_df.loc[:, 7].to_numpy()\n",
    "    X = X[:327, :]\n",
    "    labels_true = labels_true[:327]\n",
    "\n",
    "elif dataset_str == 'VERTEBRAL':\n",
    "    vertebral_df = pd.read_csv(\"../data/data-sets/vertebral.data\",\n",
    "                               skiprows=[0], header=None, delimiter=\" \")\n",
    "    X = vertebral_df.loc[:, 0:5].to_numpy()\n",
    "    labels_df = pd.read_csv(\"../data/reference-labelling/vertebral.ref\",\n",
    "                            skiprows=[0], header=None, delimiter=\" \")\n",
    "    labels_true = labels_df.to_numpy()\n",
    "\n",
    "elif dataset_str == 'SEGMENTATION':\n",
    "    segmentation_df = pd.read_csv(\"../data/data-sets/segmentation.data\",\n",
    "                                  skiprows=[0], header=None, delimiter=\" \")\n",
    "    X = segmentation_df.loc[:, 0:4].to_numpy()\n",
    "    labels_df = pd.read_csv(\"../data/reference-labelling/segmentation.ref\",\n",
    "                            skiprows=[0], header=None, delimiter=\" \")\n",
    "    labels_true = labels_df.to_numpy()\n",
    "\n",
    "elif dataset_str == 'USER':\n",
    "    user_df = pd.read_csv(\"../data/data-sets/user.data\",\n",
    "                          skiprows=[0], header=None, delimiter=\" \")\n",
    "    X = user_df.loc[:, 0:4].to_numpy()\n",
    "    labels_df = pd.read_csv(\"../data/reference-labelling/user.ref\",\n",
    "                            skiprows=[0], header=None, delimiter=\" \")\n",
    "    labels_true = labels_df.to_numpy()\n",
    "\n",
    "else:\n",
    "    dataGenerator = dataGen()\n",
    "    P, V_true, X = dataGenerator.generateCircles()\n",
    "    labels_true = partition_to_labels(V_true)\n",
    "\n",
    "labels_true = generate_int_labels(labels_true)\n",
    "M = len(np.unique(labels_true))\n",
    "\n",
    "print(f'{dataset_str} dataset with {X.shape[1]} features, {X.shape[0]} samples and {M} classes.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9318859-09b8-4206-92cd-95dbafcaf442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Percentage: 0\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      " Annealing Algorithm: final beta = 0.5\n",
      "Starting with beta = 1\n",
      "*************************Clustering Finished!*************************\n",
      "Starting with beta = 0.5\n",
      "*************************Clustering Finished!*************************\n",
      "********** Sequential Algorithm: 1.0**********\n",
      "*************************Clustering Finished!*************************\n",
      "********** Sequential Algorithm: 0.5**********\n",
      "*************************Clustering Finished!*************************\n",
      " beta=[1.  0.5]\n",
      " annealing: NMI = [0.58252099 0.84955134] \n",
      " sequential: NMI = [1.         0.82537199] \n",
      "Iteration: 0, Percentage: 0.1\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      " Annealing Algorithm: final beta = 0.5\n",
      "Starting with beta = 1\n",
      "*************************Clustering Finished!*************************\n",
      "Starting with beta = 0.5\n",
      "*************************Clustering Finished!*************************\n",
      "********** Sequential Algorithm: 1.0**********\n",
      "*************************Clustering Finished!*************************\n",
      "********** Sequential Algorithm: 0.5**********\n",
      "*************************Clustering Finished!*************************\n",
      " beta=[1.  0.5]\n",
      " annealing: NMI = [1.         0.84955134] \n",
      " sequential: NMI = [1.         0.84955134] \n",
      "Iteration: 0, Percentage: 0.2\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      " Annealing Algorithm: final beta = 0.5\n",
      "Starting with beta = 1\n",
      "*************************Clustering Finished!*************************\n",
      "Starting with beta = 0.5\n",
      "*************************Clustering Finished!*************************\n",
      "********** Sequential Algorithm: 1.0**********\n",
      "*************************Clustering Finished!*************************\n",
      "********** Sequential Algorithm: 0.5**********\n",
      "*************************Clustering Finished!*************************\n",
      " beta=[1.  0.5]\n",
      " annealing: NMI = [1.         0.87782188] \n",
      " sequential: NMI = [1.         0.87782188] \n",
      "Iteration: 0, Percentage: 0.3\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      " Annealing Algorithm: final beta = 0.5\n",
      "Starting with beta = 1\n",
      "*************************Clustering Finished!*************************\n",
      "Starting with beta = 0.5\n",
      "*************************Clustering Finished!*************************\n",
      "********** Sequential Algorithm: 1.0**********\n",
      "*************************Clustering Finished!*************************\n",
      "********** Sequential Algorithm: 0.5**********\n",
      "*************************Clustering Finished!*************************\n",
      " beta=[1.  0.5]\n",
      " annealing: NMI = [1. 1.] \n",
      " sequential: NMI = [1. 1.] \n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------#\n",
    "# Parameters\n",
    "\n",
    "final_beta=0.5\n",
    "step_size=-0.5\n",
    "\n",
    "N_iter=1\n",
    "knns=20\n",
    "restarts=5\n",
    "percentage_vec=[0,0.1,0.2,0.3]\n",
    "flag_save_results=False\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "for iteration, percentage in itertools.product(range(N_iter), percentage_vec):\n",
    "\n",
    "    print(f'Iteration: {iteration}, Percentage: {percentage}')\n",
    "    #--------------------------------------------------------------------------#\n",
    "    # Initialize and generate constraints\n",
    "    comac = CoMaC(M=M, knns=knns, restarts=restarts)\n",
    "    comac.constraints(X, labels_true, percentage=percentage,\n",
    "                      wrong_percentage=0, ClassLabels='All')\n",
    "    #--------------------------------------------------------------------------#\n",
    "\n",
    "    #--------------------------------------------------------------------------#\n",
    "    # Annealing algorithm\n",
    "    print('~'*80 + f'\\n Annealing Algorithm: final beta = {final_beta}')\n",
    "    cost_ann, V_ann, beta_vec = comac.cluster_ann(X, final_beta=final_beta, \n",
    "                                                  step_size=step_size)\n",
    "    #--------------------------------------------------------------------------#\n",
    "\n",
    "    #--------------------------------------------------------------------------#\n",
    "    # Sequential algorithm\n",
    "    V_seq = np.zeros_like(V_ann)\n",
    "    cost_seq = np.zeros_like(beta_vec)\n",
    "    for idx, beta in enumerate(beta_vec):\n",
    "        print('*'*10 + f' Sequential Algorithm: {beta}' + '*'*10)\n",
    "        cost, V = comac.cluster_seq(X, beta=beta)\n",
    "        cost_seq[idx] = cost\n",
    "        V_seq[idx,:,:] = V\n",
    "    #--------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "    #--------------------------------------------------------------------------#\n",
    "    # Generate labels, compute NMI\n",
    "    NMI_ann = np.zeros_like(beta_vec)\n",
    "    NMI_seq = np.zeros_like(beta_vec)\n",
    "    labels_ann = []\n",
    "    labels_seq = []\n",
    "\n",
    "    for idx, beta in enumerate(beta_vec):\n",
    "        labels_ann.append( partition_to_labels(V_ann[idx, :, :]) )\n",
    "        labels_seq.append( partition_to_labels(V_seq[idx, :, :]) )\n",
    "        NMI_ann[idx] = normalized_mutual_info_score(labels_true,\n",
    "                                                    labels_ann[-1])\n",
    "        NMI_seq[idx] = normalized_mutual_info_score(labels_true,\n",
    "                                                    labels_seq[-1])\n",
    "        \n",
    "    print(f' beta={beta_vec}\\n annealing: NMI = {NMI_ann} \\n sequential: NMI = {NMI_seq} ')\n",
    "    #--------------------------------------------------------------------------#\n",
    "\n",
    "    #--------------------------------------------------------------------------#\n",
    "    # Save results\n",
    "    if flag_save_results:\n",
    "\n",
    "        save_results(iteration=iteration, \n",
    "                     dataset_str=dataset_str, \n",
    "                     beta_vec=beta_vec, \n",
    "                     knns=knns, \n",
    "                     restarts=restarts, \n",
    "                     labels_ann=labels_ann, \n",
    "                     labels_seq=labels_seq, \n",
    "                     NMI_ann=NMI_ann, \n",
    "                     NMI_seq=NMI_seq,\n",
    "                     percentage=percentage, \n",
    "                     csv_string='Results.csv')\n",
    "    #--------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80fb004-3bf7-4014-8e8d-09ab681e48be",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid DarkKhaki\"> </hr>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
