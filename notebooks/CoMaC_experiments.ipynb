{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd05759b",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid RosyBrown\"> </hr>\n",
    "<hr style=\"border:1px solid Wheat\"> </hr>\n",
    "\n",
    "# Constrained Markov Clustering\n",
    "\n",
    "<hr style=\"border:1px solid Wheat\"> </hr>\n",
    "<hr style=\"border:2px solid RosyBrown\"> </hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacd5a2a",
   "metadata": {},
   "source": [
    "Load all packages and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdb2bae0-4c9a-488a-940b-cedfa933c2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "# Import modules\n",
    "from sklearn import datasets, decomposition\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "# Import custom classes and functions\n",
    "module_path = os.path.abspath(os.path.join('../src'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.insert(0, module_path)\n",
    "    \n",
    "from models.data_gen import dataGen\n",
    "from models.CoMaC import CoMaC\n",
    "\n",
    "from utils.callback import save_results\n",
    "from utils.helperFunc import partition_to_labels, generate_int_labels\n",
    "from utils.plotting import show_clustering, show_transition_prob\n",
    "#------------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b4157a54-9e86-45dc-ac25-38602a4d4486",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "USER dataset with 5 features, 403 samples and 4 classes.\n"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------#\n",
    "# Select from different datasets\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "dataset_str = 'USER'\n",
    "\n",
    "if dataset_str == 'IRIS':\n",
    "    iris = datasets.load_iris()\n",
    "    X = iris.data[:, :]\n",
    "    labels_true = iris.target\n",
    "\n",
    "elif dataset_str == 'WINE':\n",
    "    wine = datasets.load_wine()\n",
    "    X = wine.data[:, :]\n",
    "    labels_true = wine.target\n",
    "\n",
    "elif dataset_str == 'WINE_SCALED':\n",
    "    wine_df = pd.read_csv(\"../data/rand_samples_links/wine-scaled.in\",\n",
    "                          header=None, delimiter=\",\")\n",
    "    X = wine_df.loc[:, 0:12].to_numpy()\n",
    "    labels_true = wine_df.loc[:,13].to_numpy()\n",
    "\n",
    "elif dataset_str == 'GLASS':\n",
    "    glass_df = pd.read_csv(\"../data/data-sets/glass.csv\", header=None)\n",
    "    X = glass_df.loc[:, 0:8].to_numpy()\n",
    "    labels_true = glass_df.loc[:, 9].to_numpy()\n",
    "\n",
    "elif dataset_str == 'ECOLI':\n",
    "    ecoli_df = pd.read_csv(\"../data/data-sets/ecoli.csv\", header=None)\n",
    "    X = ecoli_df.loc[:, 0:6].to_numpy()\n",
    "    pca = decomposition.PCA(n_components=5)\n",
    "    pca.fit(X)\n",
    "    X = pca.transform(X)\n",
    "    labels_true = ecoli_df.loc[:, 7].to_numpy()\n",
    "    X = X[:327, :]\n",
    "    labels_true = labels_true[:327]\n",
    "\n",
    "elif dataset_str == 'VERTEBRAL':\n",
    "    vertebral_df = pd.read_csv(\"../data/data-sets/vertebral.data\",\n",
    "                               skiprows=[0], header=None, delimiter=\" \")\n",
    "    X = vertebral_df.loc[:, 0:5].to_numpy()\n",
    "    labels_df = pd.read_csv(\"../data/reference-labelling/vertebral.ref\",\n",
    "                            skiprows=[0], header=None, delimiter=\" \")\n",
    "    labels_true = labels_df.to_numpy()\n",
    "\n",
    "elif dataset_str == 'SEGMENTATION':\n",
    "    segmentation_df = pd.read_csv(\"../data/data-sets/segmentation.data\",\n",
    "                                  skiprows=[0], header=None, delimiter=\" \")\n",
    "    X = segmentation_df.loc[:, 0:4].to_numpy()\n",
    "    labels_df = pd.read_csv(\"../data/reference-labelling/segmentation.ref\",\n",
    "                            skiprows=[0], header=None, delimiter=\" \")\n",
    "    labels_true = labels_df.to_numpy()\n",
    "\n",
    "elif dataset_str == 'USER':\n",
    "    user_df = pd.read_csv(\"../data/data-sets/user.data\",\n",
    "                          skiprows=[0], header=None, delimiter=\" \")\n",
    "    X = user_df.loc[:, 0:4].to_numpy()\n",
    "    labels_df = pd.read_csv(\"../data/reference-labelling/user.ref\",\n",
    "                            skiprows=[0], header=None, delimiter=\" \")\n",
    "    labels_true = labels_df.to_numpy()\n",
    "\n",
    "else:\n",
    "    dataGenerator = dataGen()\n",
    "    P, V_true, X = dataGenerator.generateCircles()\n",
    "    labels_true = partition_to_labels(V_true)\n",
    "\n",
    "labels_true = generate_int_labels(labels_true)\n",
    "M = len(np.unique(labels_true))\n",
    "\n",
    "print(f'{dataset_str} dataset with {X.shape[1]} features, {X.shape[0]} samples and {M} classes.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d9318859-09b8-4206-92cd-95dbafcaf442",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 0, Percentage: 0\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      " Annealing Algorithm: final beta = 0.5\n",
      "Starting with beta = 1\n",
      "*************************Clustering Finished!*************************\n",
      "Starting with beta = 0.5\n",
      "*************************Clustering Finished!*************************\n",
      "********** Sequential Algorithm: 1.0**********\n",
      "*************************Clustering Finished!*************************\n",
      "********** Sequential Algorithm: 0.5**********\n",
      "*************************Clustering Finished!*************************\n",
      " beta=[1.  0.5]\n",
      " annealing: NMI = [0.28567836 0.32327685] \n",
      " sequential: NMI = [0.28501465 0.47879697] \n",
      "add row\n",
      "add row\n",
      "add row\n",
      "add row\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '..\\\\data\\\\results\\\\Results.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10340/3290855484.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mflag_save_results\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m         save_results(iteration=iteration, \n\u001b[0m\u001b[0;32m     67\u001b[0m                      \u001b[0mdataset_str\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset_str\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m                      \u001b[0mbeta_vec\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbeta_vec\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\Constrained-Markov-Aggregation-Clustering\\src\\utils\\callback.py\u001b[0m in \u001b[0;36msave_results\u001b[1;34m(iteration, dataset_str, beta_vec, knns, restarts, labels_ann, labels_seq, NMI_ann, NMI_seq, percentage, wrong_percentage, ClassLabels, csv_string)\u001b[0m\n\u001b[0;32m     68\u001b[0m             \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdict_add\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 70\u001b[1;33m     \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3385\u001b[0m         )\n\u001b[0;32m   3386\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3387\u001b[1;33m         return DataFrameRenderer(formatter).to_csv(\n\u001b[0m\u001b[0;32m   3388\u001b[0m             \u001b[0mpath_or_buf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3389\u001b[0m             \u001b[0mline_terminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\format.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m   1081\u001b[0m             \u001b[0mformatter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1082\u001b[0m         )\n\u001b[1;32m-> 1083\u001b[1;33m         \u001b[0mcsv_formatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1084\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1085\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcreated_buffer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \"\"\"\n\u001b[0;32m    227\u001b[0m         \u001b[1;31m# apply compression and byte/text conversion\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 228\u001b[1;33m         with get_handle(\n\u001b[0m\u001b[0;32m    229\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"replace\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m             \u001b[1;31m# Encoding\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m             handle = open(\n\u001b[0m\u001b[0;32m    643\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '..\\\\data\\\\results\\\\Results.csv'"
     ]
    }
   ],
   "source": [
    "#------------------------------------------------------------------------------#\n",
    "# Parameters\n",
    "\n",
    "final_beta=0.5\n",
    "step_size=-1\n",
    "\n",
    "N_iter=1\n",
    "knns=20\n",
    "restarts=5\n",
    "percentage_vec=[0,0.1,0.2,0.3]\n",
    "flag_save_results=True\n",
    "\n",
    "#------------------------------------------------------------------------------#\n",
    "\n",
    "for iteration, percentage in itertools.product(range(N_iter), percentage_vec):\n",
    "\n",
    "    print(f'Iteration: {iteration}, Percentage: {percentage}')\n",
    "    #--------------------------------------------------------------------------#\n",
    "    # Initialize and generate constraints\n",
    "    comac = CoMaC(M=M, knns=knns, restarts=restarts)\n",
    "    comac.constraints(X, labels_true, percentage=percentage,\n",
    "                      wrong_percentage=0, ClassLabels='All')\n",
    "    #--------------------------------------------------------------------------#\n",
    "\n",
    "    #--------------------------------------------------------------------------#\n",
    "    # Annealing algorithm\n",
    "    print('~'*80 + f'\\n Annealing Algorithm: final beta = {final_beta}')\n",
    "    cost_ann, V_ann, beta_vec = comac.cluster_ann(X, final_beta=final_beta, \n",
    "                                                  step_size=step_size)\n",
    "    #--------------------------------------------------------------------------#\n",
    "\n",
    "    #--------------------------------------------------------------------------#\n",
    "    # Sequential algorithm\n",
    "    V_seq = np.zeros_like(V_ann)\n",
    "    cost_seq = np.zeros_like(beta_vec)\n",
    "    for idx, beta in enumerate(beta_vec):\n",
    "        print('*'*10 + f' Sequential Algorithm: {beta}' + '*'*10)\n",
    "        cost, V = comac.cluster_seq(X, beta=beta)\n",
    "        cost_seq[idx] = cost\n",
    "        V_seq[idx,:,:] = V\n",
    "    #--------------------------------------------------------------------------#\n",
    "\n",
    "\n",
    "    #--------------------------------------------------------------------------#\n",
    "    # Generate labels, compute NMI\n",
    "    NMI_ann = np.zeros_like(beta_vec)\n",
    "    NMI_seq = np.zeros_like(beta_vec)\n",
    "    labels_ann = []\n",
    "    labels_seq = []\n",
    "\n",
    "    for idx, beta in enumerate(beta_vec):\n",
    "        labels_ann.append( partition_to_labels(V_ann[idx, :, :]) )\n",
    "        labels_seq.append( partition_to_labels(V_seq[idx, :, :]) )\n",
    "        NMI_ann[idx] = normalized_mutual_info_score(labels_true,\n",
    "                                                    labels_ann[-1])\n",
    "        NMI_seq[idx] = normalized_mutual_info_score(labels_true,\n",
    "                                                    labels_seq[-1])\n",
    "        \n",
    "    print(f' beta={beta_vec}\\n annealing: NMI = {NMI_ann} \\n sequential: NMI = {NMI_seq} ')\n",
    "    #--------------------------------------------------------------------------#\n",
    "\n",
    "    #--------------------------------------------------------------------------#\n",
    "    # Save results\n",
    "    if flag_save_results:\n",
    "\n",
    "        save_results(iteration=iteration, \n",
    "                     dataset_str=dataset_str, \n",
    "                     beta_vec=beta_vec, \n",
    "                     knns=knns, \n",
    "                     restarts=restarts, \n",
    "                     labels_ann=labels_ann, \n",
    "                     labels_seq=labels_seq, \n",
    "                     NMI_ann=NMI_ann, \n",
    "                     NMI_seq=NMI_seq,\n",
    "                     percentage=percentage, \n",
    "                     csv_string='Results.csv')\n",
    "    #--------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80fb004-3bf7-4014-8e8d-09ab681e48be",
   "metadata": {},
   "source": [
    "<hr style=\"border:2px solid DarkKhaki\"> </hr>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
